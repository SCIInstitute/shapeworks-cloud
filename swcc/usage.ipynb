{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9739759",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install swcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f34f8ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import getpass\n",
    "\n",
    "from swcc.api import swcc_session\n",
    "from swcc.models import (\n",
    "    Dataset, GroomedSegmentation, OptimizedParticles,\n",
    "    OptimizedShapeModel, Project, Segmentation, Subject\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a7a220d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34mdata/dataset_1\u001b[00m\r\n",
      "├── project_1.csv\r\n",
      "├── subject_1_groomed_segmentation_1.nrrd\r\n",
      "├── subject_1_groomed_segmentation_2.nrrd\r\n",
      "├── subject_1_groomed_segmentation_3.nrrd\r\n",
      "├── subject_1_groomed_segmentation_4.nrrd\r\n",
      "├── subject_1_groomed_segmentation_5.nrrd\r\n",
      "├── subject_1_particles_local_1.txt\r\n",
      "├── subject_1_particles_local_2.txt\r\n",
      "├── subject_1_particles_local_3.txt\r\n",
      "├── subject_1_particles_local_4.txt\r\n",
      "├── subject_1_particles_local_5.txt\r\n",
      "├── subject_1_particles_transform_1.txt\r\n",
      "├── subject_1_particles_transform_2.txt\r\n",
      "├── subject_1_particles_transform_3.txt\r\n",
      "├── subject_1_particles_transform_4.txt\r\n",
      "├── subject_1_particles_transform_5.txt\r\n",
      "├── subject_1_particles_world_1.txt\r\n",
      "├── subject_1_particles_world_2.txt\r\n",
      "├── subject_1_particles_world_3.txt\r\n",
      "├── subject_1_particles_world_4.txt\r\n",
      "├── subject_1_particles_world_5.txt\r\n",
      "├── subject_1_pre_alignment_1.txt\r\n",
      "├── subject_1_pre_alignment_2.txt\r\n",
      "├── subject_1_pre_alignment_3.txt\r\n",
      "├── subject_1_pre_alignment_4.txt\r\n",
      "├── subject_1_pre_alignment_5.txt\r\n",
      "├── subject_1_pre_cropping_1.txt\r\n",
      "├── subject_1_pre_cropping_2.txt\r\n",
      "├── subject_1_pre_cropping_3.txt\r\n",
      "├── subject_1_pre_cropping_4.txt\r\n",
      "├── subject_1_pre_cropping_5.txt\r\n",
      "├── subject_1_raw_segmentation_1.nrrd\r\n",
      "├── subject_1_raw_segmentation_2.nrrd\r\n",
      "├── subject_1_raw_segmentation_3.nrrd\r\n",
      "├── subject_1_raw_segmentation_4.nrrd\r\n",
      "├── subject_1_raw_segmentation_5.nrrd\r\n",
      "├── subject_2_groomed_segmentation_1.nrrd\r\n",
      "├── subject_2_groomed_segmentation_2.nrrd\r\n",
      "├── subject_2_groomed_segmentation_3.nrrd\r\n",
      "├── subject_2_groomed_segmentation_4.nrrd\r\n",
      "├── subject_2_groomed_segmentation_5.nrrd\r\n",
      "├── subject_2_particles_local_1.txt\r\n",
      "├── subject_2_particles_local_2.txt\r\n",
      "├── subject_2_particles_local_3.txt\r\n",
      "├── subject_2_particles_local_4.txt\r\n",
      "├── subject_2_particles_local_5.txt\r\n",
      "├── subject_2_particles_transform_1.txt\r\n",
      "├── subject_2_particles_transform_2.txt\r\n",
      "├── subject_2_particles_transform_3.txt\r\n",
      "├── subject_2_particles_transform_4.txt\r\n",
      "├── subject_2_particles_transform_5.txt\r\n",
      "├── subject_2_particles_world_1.txt\r\n",
      "├── subject_2_particles_world_2.txt\r\n",
      "├── subject_2_particles_world_3.txt\r\n",
      "├── subject_2_particles_world_4.txt\r\n",
      "├── subject_2_particles_world_5.txt\r\n",
      "├── subject_2_pre_alignment_1.txt\r\n",
      "├── subject_2_pre_alignment_2.txt\r\n",
      "├── subject_2_pre_alignment_3.txt\r\n",
      "├── subject_2_pre_alignment_4.txt\r\n",
      "├── subject_2_pre_alignment_5.txt\r\n",
      "├── subject_2_pre_cropping_1.txt\r\n",
      "├── subject_2_pre_cropping_2.txt\r\n",
      "├── subject_2_pre_cropping_3.txt\r\n",
      "├── subject_2_pre_cropping_4.txt\r\n",
      "├── subject_2_pre_cropping_5.txt\r\n",
      "├── subject_2_raw_segmentation_1.nrrd\r\n",
      "├── subject_2_raw_segmentation_2.nrrd\r\n",
      "├── subject_2_raw_segmentation_3.nrrd\r\n",
      "├── subject_2_raw_segmentation_4.nrrd\r\n",
      "└── subject_2_raw_segmentation_5.nrrd\r\n",
      "\r\n",
      "0 directories, 71 files\r\n"
     ]
    }
   ],
   "source": [
    "# generate some fake data files to upload\n",
    "! rm -fr data; mkdir -p data/dataset_1 data/downloads\n",
    "! touch data/dataset_1/subject_{1,2}_{raw,groomed}_segmentation_{1,2,3,4,5}.nrrd\n",
    "! touch data/dataset_1/subject_{1,2}_{pre_alignment,pre_cropping}_{1,2,3,4,5}.txt\n",
    "! touch data/dataset_1/project_1.csv\n",
    "! touch data/dataset_1/subject_{1,2}_particles_{local,world,transform}_{1,2,3,4,5}.txt\n",
    "! for f in data/dataset_1/* ; do echo 'content' > $f ; done\n",
    "! tree data/dataset_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa5aa4f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "username········\n",
      "password········\n",
      "[(6, 'test1'), (7, 'test2')]\n"
     ]
    }
   ],
   "source": [
    "# Ordinarily, you will want to use the api as a context manager, like this:\n",
    "base_url = 'http://localhost:8000/api/v1'\n",
    "\n",
    "with swcc_session(base_url) as session:\n",
    "    token = session.login(getpass.getpass('username'), getpass.getpass('password'))\n",
    "    \n",
    "    print([(d.id, d.name) for d in Dataset.list()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2eb23385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(6, 'test1'), (7, 'test2')]\n"
     ]
    }
   ],
   "source": [
    "# For development, it is possible to generate a session outside of a context manager.\n",
    "ctx = swcc_session(base_url, token=token)\n",
    "session = ctx.__enter__()\n",
    "\n",
    "print([(d.id, d.name) for d in Dataset.list()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7dabf856",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset(id=None, name='test dataset', license='license', description='just a test', acknowledgement='NIH', keywords='', contributors='', publications='')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All domain models are pydantic models that can be created in offline mode:\n",
    "dataset = Dataset(name='test dataset', license='license', description='just a test', acknowledgement='NIH')\n",
    "\n",
    "# Note that it is missing an `id`.\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "813b4a6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset(id=26, name='test dataset', license='license', description='just a test', acknowledgement='NIH', keywords='', contributors='', publications='')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To generate the entity on the server, you must call its `create` method\n",
    "dataset.create()\n",
    "\n",
    "# Now its id exists\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d00e1a99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset(id=26, name='test dataset', license='license', description='just a test', acknowledgement='NIH', keywords='', contributors='', publications='')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Given an id, you can fetch data from the server\n",
    "dataset_id = dataset.id\n",
    "Dataset.from_id(dataset_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "912a616d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id=6 name='test1' license='license' description='sdfs' acknowledgement='sfsdf' keywords='' contributors='' publications=''\n",
      "id=7 name='test2' license='license' description='sdfs' acknowledgement='sfsdf' keywords='' contributors='' publications=''\n",
      "id=26 name='test dataset' license='license' description='just a test' acknowledgement='NIH' keywords='' contributors='' publications=''\n"
     ]
    }
   ],
   "source": [
    "# You can also list all entities on the server using the `list` method\n",
    "for d in Dataset.list():\n",
    "    print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4a61aa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mReceived:\n",
      "{\n",
      "  \"detail\": \"Not found.\"\n",
      "}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "ename": "HTTPError",
     "evalue": "404 Client Error: Not Found for url: http://localhost:8000/api/v1/datasets/26/",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-e1e4be6f718d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Now we find it no longer exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/afi/shapeworks-cloud/swcc/swcc/models.py\u001b[0m in \u001b[0;36mfrom_id\u001b[0;34m(cls, id, **kwargs)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{cls._endpoint}/{id}/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m         \u001b[0mjson\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__fields__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/afi/shapeworks-cloud/swcc/swcc/utils.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(response)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTTPError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/afi/env/lib/python3.8/site-packages/requests/models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    938\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 940\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    941\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    942\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mHTTPError\u001b[0m: 404 Client Error: Not Found for url: http://localhost:8000/api/v1/datasets/26/"
     ]
    }
   ],
   "source": [
    "# Entities are deleted from the server using the `delete` method\n",
    "dataset.delete()\n",
    "\n",
    "# Now we find it no longer exists\n",
    "Dataset.from_id(dataset_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "750b38aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is an example of using the API to upload a dataset\n",
    "p = Path('data') / 'dataset_1'\n",
    "\n",
    "dataset = Dataset(name='test dataset', license='license', description='just a test', acknowledgement='NIH').create()\n",
    "project = Project(file=p / 'project_1.csv').create()\n",
    "shape_model = project.add_shape_model(\n",
    "    parameters={\n",
    "        'number_of_particles': 128,\n",
    "    }\n",
    ")\n",
    "\n",
    "for subject_name in ['subject_1', 'subject_2']:\n",
    "    subject = dataset.add_subject(subject_name)\n",
    "    \n",
    "    for id_ in range(1, 6):\n",
    "        segmentation = subject.add_segmentation(\n",
    "            file=p / f'{subject_name}_raw_segmentation_{id_}.nrrd',\n",
    "            anatomy_type='knee',\n",
    "        )\n",
    "        groomed_segmentation = project.add_groomed_segmentation(\n",
    "            file=p / f'{subject_name}_groomed_segmentation_{id_}.nrrd',\n",
    "            segmentation=segmentation,\n",
    "            pre_cropping=p / f'{subject_name}_pre_cropping_{id_}.txt',\n",
    "            pre_alignment=p / f'{subject_name}_pre_alignment_{id_}.txt',\n",
    "        )\n",
    "        particles = shape_model.add_particles(\n",
    "            world=p / f'{subject_name}_particles_world_{id_}.txt',\n",
    "            local=p / f'{subject_name}_particles_local_{id_}.txt',\n",
    "            transform=p / f'{subject_name}_particles_transform_{id_}.txt',\n",
    "            groomed_segmentation=groomed_segmentation,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bcd0e591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anatomy type: knee\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'number_of_particles': 128}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we can explore the data using the models\n",
    "segmentation = next(subject.segmentations)\n",
    "print(f'Anatomy type: {segmentation.anatomy_type}')\n",
    "\n",
    "shape_models = next(project.shape_models)\n",
    "shape_models.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b15a1f83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download url:\n",
      "http://localhost:9000/django-storage/688246ce-5ce4-401e-88a2-1d24be9212c3/subject_2_raw_segmentation_1.nrrd?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=minioAccessKey%2F20210524%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20210524T050241Z&X-Amz-Expires=604800&X-Amz-SignedHeaders=host&X-Amz-Signature=cd8cca0cd3e80d505fe43539319152addd7ab79f866f68b0f4765cfbe108df0c\n",
      "\n",
      "Downloaded downloads/subject_2_raw_segmentation_1.nrrd...\n",
      "\n",
      "Downloaded downloads/groomed/subject_1_groomed_segmentation_1.nrrd...\n",
      "Downloaded downloads/groomed/subject_1_pre_cropping_1.txt...\n",
      "Downloaded downloads/groomed/subject_1_pre_alignment_1.txt...\n"
     ]
    }
   ],
   "source": [
    "# The entities contain urls to download the associated files\n",
    "print('Download url:')\n",
    "print(segmentation.file.url)\n",
    "\n",
    "print('')\n",
    "\n",
    "# There is a helper method to download the file to a provided path\n",
    "print(f\"Downloaded {segmentation.file.download('downloads')}...\")\n",
    "\n",
    "print('')\n",
    "\n",
    "# There is also a helper method on models to download all files attached to them\n",
    "groomed = next(project.groomed_segmentations)\n",
    "for download in groomed.download_files('downloads/groomed'):\n",
    "    print(f'Downloaded {download}...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b6afce20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up\n",
    "dataset.delete()\n",
    "project.delete()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
